# MPI local
load("./Data/OPTIMA_Cytokine_PreprocessedData.RData")
# Index participants with minimum of two BDI observations
ids_with_bdi = dat[, paste0("t", 0:7, "_bdi")] %>% is.na() %>% rowSums < 7
## Load cytokine reference
# Slurmgate
#load("/binder/mgp/datasets/2020_ImmuneDepression/cytokine/Nils_Preprocessed/Cytokine_Reference.RData")
# MPI local
load("./Data/Cytokine_Reference.RData")
## Define parameters
x = c("t0_bdi_std", "sex_std", "age_std", "BMI_std")
data = dat[ids_with_bdi,]
y = "t7_bdi_locf"
k.outer = 5
k.inner = 5
num_repeats = 5
perm.test = FALSE
runGLMnet = TRUE
runRF = TRUE
runKNN = TRUE
runSVM = FALSE
runBART = FALSE
## Subset data to relevant variables only
data = data[, c(x, y)]
## Create folds
obs.all = nrow(data)
fold.pool.outer = rep_len(sample(1:k.outer), length.out = obs.all)
## Define fitControl object for caret
fitControl = trainControl(method = "cv",
number = k.inner)
## Define used models
used.models = c()
if(runGLMnet)  {used.models = c(used.models, "glmnet")}
if(runRF)  {used.models = c(used.models, "rf")}
if(runSVM)  {used.models = c(used.models, "svm")}
if(runNNET)  {used.models = c(used.models, "nnet")}
if(runBART)  {used.models = c(used.models, "bart")}
runNNET = FALSE
used.models = c()
if(runGLMnet)  {used.models = c(used.models, "glmnet")}
if(runRF)  {used.models = c(used.models, "rf")}
if(runKNN)  {used.models = c(used.models, "knn")}
if(runSVM)  {used.models = c(used.models, "svm")}
if(runNNET)  {used.models = c(used.models, "nnet")}
if(runBART)  {used.models = c(used.models, "bart")}
## Define tuneGrids
glmnet.tuneGrid = expand.grid(alpha = seq(from = 0, to = 1, by = 0.2),
lambda = seq(from = 0, to = 1, by = 0.2))
rf.tuneGrid = data.frame(mtry = unique(round(seq(from = 2, to = length(x), length.out = 5))))
knn.tuneGrid = expand.grid(k = 1:10)
svm.tuneGrid = expand.grid(degree = 1:3,
scale = c(0.001, 0.01, 0.1),
C = c(0.25, 0.5, 1))
nnet.tuneGrid = expand.grid(size = seq(from = 1, to = 10, by = 2),
decay = seq(from = 0.1, to = 0.5, by = 0.1))
bart.tuneGrid = expand.grid(num_trees = c(10, 15, 20, 50),
k = 2,
alpha = 0.95,
beta = 2,
nu = 3)
## Create output data.frame for fit statistics
fit.stats = expand.grid(num_repeat = 1:num_repeats,
k = 1:k.outer,
model = used.models)
fit.stats[, c("RMSE", "Rsquared", "MAE", "alpha", "lambda", "mtry", "k.knn",
"degree", "scale", "C", "size", "decay",
"num_trees", "k.bart", "beta", "nu")] = NA
## Create output data.frame for variable importance
varImp.stats = fit.stats[, c("num_repeat", "k", "model")]
varImp.stats[, sort(x)] = NA
## Create output data.frame for individual predictions
# Save rowID
data$rowID = paste0("r", 1:nrow(data))
# Create data.frame
pred.stats = expand.grid(num_repeat = 1:num_repeats,
model = used.models)
pred.stats[, unique(data$rowID)] = NA
repeats = 1
## Print repeat number to index progress
cat(paste0("\nRepeat no.:\t\t", repeats))
## Assign folds
data$fold.outer = sample(fold.pool.outer)
outer = 1
## Print outer fold number to index progress
cat(paste0("\n---Outer CV-Fold no.:\t", outer))
## Divide data into train and test sets
train = data[data$fold.outer != outer,]
test = data[data$fold.outer == outer,]
## Run inner CV
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "glmnet")
## Save final tuning parameters
fit.stats[fit.stats.index, c("alpha", "lambda")] = glmnet.fit$bestTune
## Predict in independent test set
glmnet.preds = predict(glmnet.fit, newdata = test)
# Save predictions
pred.stats[pred.stats$num_repeat == repeats & pred.stats$model == "glmnet",
test$rowID] = glmnet.preds
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], glmnet.preds)
## Save variable importance
glmnet.varImp = varImp(glmnet.fit)$importance
# save variable label and order by label
glmnet.varImp$vars = row.names(glmnet.varImp)
glmnet.varImp = arrange(glmnet.varImp, vars)
# Save importance values
varImp.stats[fit.stats.index, sort(x)] = glmnet.varImp$Overall
## Run inner CV
rf.fit = train(x = train[,x], y = train[,y],
method = "rf", metric = "RMSE",
trControl = fitControl,
tuneGrid = rf.tuneGrid
)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "rf")
## Save final tuning parameters
fit.stats[fit.stats.index, "mtry"] = rf.fit$finalModel$tuneValue
## Predict in independent test set
rf.preds = predict(rf.fit, newdata = test)
# Save predictions
pred.stats[pred.stats$num_repeat == repeats & pred.stats$model == "rf",
test$rowID] = rf.preds
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], rf.preds)
## Save variable importance
rf.varImp = varImp(rf.fit)$importance
# save variable label and order by label
rf.varImp$vars = row.names(rf.varImp)
rf.varImp = arrange(rf.varImp, vars)
# Save importance values
varImp.stats[fit.stats.index, sort(x)] = rf.varImp$Overall
knn.tuneGrid
## Run inner CV
knn.fit = train(x = train[,x], y = train[,y],
method = "knn", metric = "RMSE",
trControl = fitControl,
tuneGrid = knn.tuneGrid
)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "knn")
knn.fit$finalModel$tuneValue
## Save final tuning parameters
fit.stats[fit.stats.index, "k.knn"] = knn.fit$finalModel$tuneValue
sqrt(100)
## Predict in independent test set
knn.preds = predict(knn.fit, newdata = test)
# Save predictions
pred.stats[pred.stats$num_repeat == repeats & pred.stats$model == "knn",
test$rowID] = knn.preds
predict(knn.fit, newdata = test)
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], knn.preds)
## Save variable importance
knn.varImp = varImp(knn.fit)$importance
# save variable label and order by label
knn.varImp$vars = row.names(knn.varImp)
knn.varImp = arrange(knn.varImp, vars)
# Save importance values
varImp.stats[fit.stats.index, sort(x)] = knn.varImp$Overall
fit.stats[!is.na(fit.stats$RMSE)]
fit.stats[!is.na(fit.stats$RMSE),]
## Aggregate pred.stats across models using a voting system
pred.aggregate.stats = pred.aggregate(preds = pred.stats)
pred.aggregate <- function(
preds
) {
## Get rowindex
rowindex = paste0("r", 1:(ncol(preds) - 2))
## Remove prediction output for models that were not run
preds = na.omit(preds)
## Round predictions
preds[, rowindex] = round(preds[, rowindex])
## transpose
tpreds = t(preds[, rowindex])
## Get mode
pred.aggregate = apply(tpreds, 1, getmode) %>% as.vector()
return(pred.aggregate)
}
## Aggregate pred.stats across models using a voting system
pred.aggregate.stats = pred.aggregate(preds = pred.stats)
head(fit.stats)
## Subset fit.stats to fit.stats with available data
for(i in colnames(fit.stats)[7:ncol(fit.stats)])   {
if(sum(is.na(fit.stats[, i])) == nrow(fit.stats))  {fit.stats[, i] = NULL}
}
fit.stats
## Load packages
library("tidyverse")
library("ggcorrplot")
library("RColorBrewer")
library("gghalves")
library("caret")
library("glmnet")
library("PubHelper")
## Load data
# Slurmgate
#load("/binder/mgp/datasets/2020_ImmuneDepression/cytokine/Nils_Preprocessed/OPTIMA_Cytokine_PreprocessedData.RData")
# MPI local
load("./Data/OPTIMA_Cytokine_PreprocessedData.RData")
# Index participants with minimum of two BDI observations
ids_with_bdi = dat[, paste0("t", 0:7, "_bdi")] %>% is.na() %>% rowSums < 7
## Load cytokine reference
# Slurmgate
#load("/binder/mgp/datasets/2020_ImmuneDepression/cytokine/Nils_Preprocessed/Cytokine_Reference.RData")
# MPI local
load("./Data/Cytokine_Reference.RData")
## Source nested cross-validation function
source("./Scripts/functions.R")
## Define parameters
x = c("t0_bdi_std", "sex_std", "age_std", "BMI_std")
## Run analysis
set.seed(8)
covariates.base.output = nested.cv(data = dat[ids_with_bdi,],
x = x,
y = "t7_bdi_locf",
k.outer = 5,
k.inner = 5,
num_repeats = 100,
perm.test = FALSE,
runGLMnet = TRUE,
runRF = TRUE,
runKNN = TRUE,
runNNET = FALSE,
runSVM = FALSE,
runBART = FALSE)
# Save results
save(covariates.base.output, file = "./Results/covariates.base.output.RData")
## Source nested cross-validation function
source("./Scripts/functions.R")
## Define parameters
x = c("t0_bdi_std", "sex_std", "age_std", "BMI_std")
## Run analysis
set.seed(8)
covariates.base.output = nested.cv(data = dat[ids_with_bdi,],
x = x,
y = "t7_bdi_locf",
k.outer = 5,
k.inner = 5,
num_repeats = 100,
perm.test = FALSE,
runGLMnet = TRUE,
runRF = TRUE,
runKNN = TRUE,
runNNET = FALSE,
runSVM = FALSE,
runBART = FALSE)
# Save results
save(covariates.base.output, file = "./Results/covariates.base.output.RData")
str(covariates.base.output)
arrange(covariates.base.output$varImp)
summary(covariates.base.output$varImp)
summary(covariates.base.output$fit$RMSE)
with(covariates.base.output$fit, by(RMSE, model, summary))
with(covariates.base.output$fit, by(RMSE, model, sd))
## Run permutation analysis
set.seed(9)
covariates.base.perm = nested.cv(data = dat[ids_with_bdi,],
x = x,
y = "t7_bdi_locf",
k.outer = 5,
k.inner = 5,
num_repeats = 100,
perm.test = TRUE,
runGLMnet = TRUE,
runRF = TRUE,
runKNN = TRUE,
runNNET = FALSE,
runSVM = FALSE,
runBART = FALSE)
save(covariates.base.perm, file = "./Results/covariates.base.perm.RData")
summary(dat[,x])
sd(dat[,x])
View(dat)
x
warnings()
?varImp
citation("randomForest")
citation("knn")
library("knn")
.libPaths("C:/Users/nkapp/R")
## Load packages
library("tidyverse")
library("ggcorrplot")
library("RColorBrewer")
library("gghalves")
library("caret")
library("glmnet")
library("PubHelper")
## Load data
# Slurmgate
#load("/binder/mgp/datasets/2020_ImmuneDepression/cytokine/Nils_Preprocessed/OPTIMA_Cytokine_PreprocessedData.RData")
# MPI local
load("./Data/OPTIMA_Cytokine_PreprocessedData.RData")
# Index participants with minimum of two BDI observations
ids_with_bdi = dat[, paste0("t", 0:7, "_bdi")] %>% is.na() %>% rowSums < 7
## Load cytokine reference
# Slurmgate
#load("/binder/mgp/datasets/2020_ImmuneDepression/cytokine/Nils_Preprocessed/Cytokine_Reference.RData")
# MPI local
load("./Data/Cytokine_Reference.RData")
## Source nested cross-validation function
source("./Scripts/functions.R")
## Define parameters
x = cyto_ref$vars
## Define parameters
x = c(cyto_ref$vars, "t0_bdi_std", "sex_std", "age_std", "BMI_std")
## Run analysis
set.seed(12)
cytokine.comb.output = nested.cv(data = dat[ids_with_bdi,],
x = x,
y = "t7_bdi_locf",
k.outer = 5,
k.inner = 5,
num_repeats = 100,
perm.test = FALSE,
runGLMnet = TRUE,
runRF = TRUE,
runKNN = TRUE,
runNNET = FALSE,
runSVM = FALSE,
runBART = FALSE)
# Save results
save(cytokine.comb.output, file = "./Results/cytokine.comb.output.RData")
View(dat)
dat[dat$ID %in% c("PTP1291", "PTP0332"), c("ID", "age")]
colnames(dat)[grepl("birth", colnames(dat))]
dat[dat$ID %in% c("PTP1291", "PTP0332"), c("ID", "age", "birth_monthyear")]
## Run permutation analysis
set.seed(13)
cytokine.comb.perm = nested.cv(data = dat[ids_with_bdi,],
x = x,
y = "t7_bdi_locf",
k.outer = 5,
k.inner = 5,
num_repeats = 100,
perm.test = TRUE,
runGLMnet = TRUE,
runRF = TRUE,
runKNN = TRUE,
runNNET = FALSE,
runSVM = FALSE,
runBART = FALSE)
save(cytokine.comb.perm, file = "./Results/cytokine.comb.perm.RData")
load("./Results/covariates.base.output.RData")
load("./Results/covariates.base.perm.RData")
load("./Results/cytokine.base.output.RData")
load( "./Results/cytokine.base.perm.RData")
covariates.base.output$fit$pred = "Covariates"
covariates.base.output$fit$pred.type = "Model Prediction"
covariates.base.output$fit$covariates = "With covariates"
covariates.base.perm$fit$pred = "Covariates"
covariates.base.perm$fit$pred.type = "Null Model"
covariates.base.perm$fit$covariates = "With covariates"
cytokine.base.output$fit$pred = "Cytokines"
cytokine.base.output$fit$pred.type = "Model Prediction"
cytokine.base.output$fit$covariates = "Without covariates"
cytokine.base.perm$fit$pred = "Cytokines"
cytokine.base.perm$fit$pred.type = "Null Model"
cytokine.base.perm$fit$covariates = "Without covariates"
cytokine.comb.output$fit$pred = "Cytokines"
cytokine.comb.output$fit$pred.type = "Model Prediction"
cytokine.comb.output$fit$covariates = "With covariates"
cytokine.comb.perm$fit$pred = "Cytokines"
cytokine.comb.perm$fit$pred.type = "Null Model"
cytokine.comb.perm$fit$covariates = "With covariates"
# Rowbind data
fit.stats = rbind.data.frame(covariates.base.output$fit,
covariates.base.perm$fit,
cytokine.base.output$fit,
cytokine.base.perm$fit,
cytokine.comb.output$fit,
cytokine.comb.perm$fit)
## Recode model
fit.stats$algorithm = recode(fit.stats$model,
'glmnet' = "Elastic net regression",
'rf' = "Random forest",
'knn' = "k-nearest neighbour")
## Set factor levels
fit.stats$covariates = factor(fit.stats$covariates,
levels = c("Without covariates", "With covariates"))
## Get long-format varImp data
varImp.stats.comb = aggregate.varImp(cytokine.comb.output)
varImp.stats.comb.perm = aggregate.varImp(cytokine.comb.perm)
# Add Null Model/ Model Prediction specifier
varImp.stats.comb$ind$pred.type = "Model Prediction"
varImp.stats.comb.perm$ind$pred.type = "Null Model"
## Recode model
varImp.stats.comb$ind$algorithm = recode(varImp.stats.comb$ind$model,
'glmnet' = "Elastic net regression",
'rf' = "Random forest",
'knn' = "k-nearest neighbour")
varImp.stats.comb.perm$ind$algorithm = recode(varImp.stats.comb.perm$ind$model,
'glmnet' = "Elastic net regression",
'rf' = "Random forest",
'knn' = "k-nearest neighbour")
# Reorder factor levels for permutation results
varImp.stats.comb.perm$ind$var = factor(varImp.stats.comb.perm$ind$var,
levels = levels(varImp.stats.comb$ind$var))
## Combine varImp.stats
varImp.stats = rbind.data.frame(varImp.stats.comb$ind, varImp.stats.comb.perm$ind)
## Obtain test statistics
varImp.teststats = data.frame(var = levels(varImp.stats$var),
beta = NA,
se = NA,
p = NA,
q = NA)
for(i in varImp.teststats$var)   {
# Run regression
model = lm(varImp ~ pred.type + algorithm,
data = varImp.stats[varImp.stats$var == i,])
# Save results
model.results = getGLMTable(model,
exclude.covariates = c("algorithmRandom forest",
"algorithmk-nearest neighbour"),
intercept = FALSE)
varImp.teststats[varImp.teststats$var == i, c("beta", "se", "p")] =
model.results[, c("Estimate", "SE", "pval")]
}
head(varImp.teststats)
## RMSE (width=700; height=473)
ggplot(fit.stats[fit.stats$model != "bart",], aes(x = pred, y = RMSE)) +
geom_half_violin(aes(fill = pred.type), col = "black", alpha = 0.8) +
geom_half_boxplot(aes(fill = pred.type), outlier.alpha = 0, alpha = 0.8, col = "black",
errorbar.draw = TRUE, side = "r") +
geom_half_point(aes(fill = pred.type, col = pred.type), size = 0.2, alpha = 0.3) +
facet_grid(algorithm~covariates, scales = "free_x", space = "free_x") +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
#scale_y_continuous(limits = c(0, 20)) +
coord_cartesian(expand = FALSE) +
labs(x = "", y = "RMSE") +
theme_bw() +
theme(legend.position = "top",
legend.title = element_blank())
## R2  (width=750; height=507)
ggplot(fit.stats[fit.stats$model != "bart",], aes(x = pred, y = Rsquared)) +
geom_half_violin(aes(fill = pred.type), col = "black", alpha = 0.8) +
geom_half_boxplot(aes(fill = pred.type), outlier.alpha = 0, alpha = 0.8, col = "black",
errorbar.draw = TRUE, side = "r") +
geom_half_point(aes(fill = pred.type, col = pred.type), size = 0.2, alpha = 0.3) +
facet_grid(algorithm~covariates, scales = "free_x", space = "free_x") +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
#scale_y_continuous(limits = c(0, 0.5)) +
coord_cartesian(expand = FALSE) +
labs(x = "", y = expression(R^2)) +
theme_bw() +
theme(legend.position = "top",
legend.title = element_blank())
## Visualise all variables for model prediction only
ggplot(na.omit(arrange(varImp.stats.comb$ind, var)),
aes(x = var, y = varImp)) +
stat_boxplot(aes(fill = algorithm), col = "black", outlier.alpha = 0, alpha = 0.8) +
geom_jitter(aes(fill = algorithm, col = algorithm), size = 0.1, alpha = 0.3) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
scale_x_discrete(limits = rev(levels(varImp.stats.comb$ind$var))) +
facet_grid(.~algorithm) +
coord_flip() +
labs(x = "", y = "Variable Importance") +
theme_bw() +
theme(legend.position = "top",
legend.title = element_blank())
## Get long-format varImp data
varImp.stats.comb = aggregate.varImp(cytokine.comb.output)
varImp.stats.comb.perm = aggregate.varImp(cytokine.comb.perm)
str(varImp.stats.comb)
# Add Null Model/ Model Prediction specifier
varImp.stats.comb$ind$pred.type = "Model Prediction"
varImp.stats.comb.perm$ind$pred.type = "Null Model"
## Recode model
varImp.stats.comb$ind$algorithm = recode(varImp.stats.comb$ind$model,
'glmnet' = "Elastic net regression",
'rf' = "Random forest",
'knn' = "k-nearest neighbour")
varImp.stats.comb.perm$ind$algorithm = recode(varImp.stats.comb.perm$ind$model,
'glmnet' = "Elastic net regression",
'rf' = "Random forest",
'knn' = "k-nearest neighbour")
# Reorder factor levels for permutation results
varImp.stats.comb.perm$ind$var = factor(varImp.stats.comb.perm$ind$var,
levels = levels(varImp.stats.comb$ind$var))
## Combine varImp.stats
varImp.stats = rbind.data.frame(varImp.stats.comb$ind, varImp.stats.comb.perm$ind)
## Visualise all variables for model prediction only
ggplot(na.omit(arrange(varImp.stats.comb$ind, var)),
aes(x = var, y = varImp)) +
stat_boxplot(aes(fill = algorithm), col = "black", outlier.alpha = 0, alpha = 0.8) +
geom_jitter(aes(fill = algorithm, col = algorithm), size = 0.1, alpha = 0.3) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
scale_x_discrete(limits = rev(levels(varImp.stats.comb$ind$var))) +
facet_grid(.~algorithm) +
coord_flip() +
labs(x = "", y = "Variable Importance") +
theme_bw() +
theme(legend.position = "top",
legend.title = element_blank())
str(varImp.stats.comb)
