scale_color_brewer(palette = "Dark2") +
scale_y_continuous(limits = c(0, 0.5)) +
coord_cartesian(expand = FALSE) +
labs(x = "", y = expression(R^2)) +
theme_bw() +
theme(legend.position = "top",
legend.title = element_blank())
table(ids_with_bdi)
table(is.na(dat[ids_with_bdi, "t7_bdi"]))
.libPaths("C:/Users/nkapp/R")
## Load packages
library("tidyverse")
library("ggcorrplot")
library("RColorBrewer")
library("gghalves")
library("caret")
library("glmnet")
library("bartMachine")
library("PubHelper")
load("./Data/OPTIMA_Cytokine_PreprocessedData.RData")
# Index participants with minimum of two BDI observations
ids_with_bdi = dat[, paste0("t", 0:7, "_bdi")] %>% is.na() %>% rowSums < 7
load("./Data/Cytokine_Reference.RData")
## Source nested cross-validation function
source("./Scripts/functions.R")
data = dat
y = "t7_bdi_locf"
x = x
x = cyto_ref$vars
## Create folds
obs.all = nrow(data)
k.outer = 5
k.inner = 5
fold.pool.outer = rep_len(sample(1:k.outer), length.out = obs.all)
fold.pool.outer
## Define fitControl object for caret
fitControl = trainControl(method = "cv",
number = k.inner,
savePredictions = TRUE)
## Define tuneGrid
glmnet.tuneGrid = expand.grid(alpha = seq(from = 0, to = 1, by = 0.2),
lambda = seq(from = 0, to = 1, by = 0.2))
rf.tuneGrid = data.frame(mtry = unique(round(seq(from = 2, to = length(x), length.out = 5))))
## Create output data.frame for fit statistics
fit.stats = expand.grid(num_repeat = 1:num_repeats,
k = 1:k.outer,
model = c("glmnet", "rf", "bart"))
num_repeat = 10
## Create output data.frame for fit statistics
fit.stats = expand.grid(num_repeat = 1:num_repeats,
k = 1:k.outer,
model = c("glmnet", "rf", "bart"))
num_repeats = 10
## Create output data.frame for fit statistics
fit.stats = expand.grid(num_repeat = 1:num_repeats,
k = 1:k.outer,
model = c("glmnet", "rf", "bart"))
fit.stats[, c("RMSE", "Rsquared", "MAE", "alpha", "lambda", "mtry",
"num_trees", "k.bart", "beta", "nu")] = NA
## Create output data.frame for variable importance
varImp.stats = fit.stats[, c("num_repeat", "k", "model")]
varImp.stats[, sort(x)] = NA
## Create output data.frame for individual predictions
# Save rowID
data$rowID = paste0("row_", 1:nrow(data))
data$rowID
## Create output data.frame for individual predictions
# Save rowID
data$rowID = paste0("row", 1:nrow(data))
data$rowID
## Create output data.frame for individual predictions
# Save rowID
data$rowID = paste0("r", 1:nrow(data))
data$rowID
pred.stats = fit.stats[, c("num_repeat", "k", "model")]
head(pred.stats)
unique(data$rowID)
pred.stats[, unique(data$rowID)] = NA
head(pred.stats, 1)
## Print repeat number to index progress
cat(paste0("\nRepeat no.:\t\t", repeats))
repeats = 1
## Print repeat number to index progress
cat(paste0("\nRepeat no.:\t\t", repeats))
## Assign folds
data$fold.outer = sample(fold.pool.outer)
outer = 1
## Print outer fold number to index progress
cat(paste0("\n---Outer CV-Fold no.:\t", outer))
## Divide data into train and test sets
train = data[data$fold.outer != outer,]
test = data[data$fold.outer == outer,]
## Run inner CV
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "glmnet")
head(fit.stats.index)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "glmnet")
## Save final tuning parameters
fit.stats[fit.stats.index, c("alpha", "lambda")] = glmnet.fit$finalModel$tuneValue
head(fit.stats)
## Save final tuning parameters
fit.stats[fit.stats.index, c("alpha", "lambda")] = glmnet.fit$finalModel$tuneValue
## Predict in independent test set
glmnet.preds = predict(glmnet.fit, newdata = test)
test$rowID
glmnet.preds
head(pred.stats)
head(pred.stats, 1)
test$rowID
pred.stats[fit.stats.index, test$rowID]
# Save predictions
pred.stats[fit.stats.index, test$rowID] = glmnet.preds
head(pred.stats, 1)
# Create data.frame
pred.stats = expand.grid(num_repeat = 1:num_repeats,
model = c("glmnet", "rf", "bart"))
pred.stats[, unique(data$rowID)] = NA
head(pred.stats)
head(pred.stats, 1)
runGLMnet = TRUE
perm.test = FALSE
runRF = TRUE
runBART = FALSE
## Create folds
obs.all = nrow(data)
fold.pool.outer = rep_len(sample(1:k.outer), length.out = obs.all)
## Define fitControl object for caret
fitControl = trainControl(method = "cv",
number = k.inner,
savePredictions = TRUE)
## Define tuneGrid
glmnet.tuneGrid = expand.grid(alpha = seq(from = 0, to = 1, by = 0.2),
lambda = seq(from = 0, to = 1, by = 0.2))
rf.tuneGrid = data.frame(mtry = unique(round(seq(from = 2, to = length(x), length.out = 5))))
bart.tuneGrid = expand.grid(num_trees = c(10, 15, 20, 50),
k = 2,
alpha = 0.95,
beta = 2,
nu = 3)
## Create output data.frame for fit statistics
fit.stats = expand.grid(num_repeat = 1:num_repeats,
k = 1:k.outer,
model = c("glmnet", "rf", "bart"))
fit.stats[, c("RMSE", "Rsquared", "MAE", "alpha", "lambda", "mtry",
"num_trees", "k.bart", "beta", "nu")] = NA
## Create output data.frame for variable importance
varImp.stats = fit.stats[, c("num_repeat", "k", "model")]
varImp.stats[, sort(x)] = NA
## Create output data.frame for individual predictions
# Save rowID
data$rowID = paste0("r", 1:nrow(data))
# Create data.frame
pred.stats = expand.grid(num_repeat = 1:num_repeats,
model = c("glmnet", "rf", "bart"))
pred.stats[, unique(data$rowID)] = NA
## Run repeats
for(repeats in 1:num_repeats)  {
## Print repeat number to index progress
cat(paste0("\nRepeat no.:\t\t", repeats))
## Permute Y if a permutation test is indicated
if(perm.test == TRUE)   {
data[, y] = sample(data[, y], replace = FALSE)
}
## Assign folds
data$fold.outer = sample(fold.pool.outer)
## Run outer CV
for(outer in 1:k.outer) {
## Print outer fold number to index progress
cat(paste0("\n---Outer CV-Fold no.:\t", outer))
## Divide data into train and test sets
train = data[data$fold.outer != outer,]
test = data[data$fold.outer == outer,]
# 1 glmnet-------------------------------------------
if(runGLMnet)  {
## Run inner CV
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "glmnet")
## Save final tuning parameters
fit.stats[fit.stats.index, c("alpha", "lambda")] = glmnet.fit$finalModel$tuneValue
## Predict in independent test set
glmnet.preds = predict(glmnet.fit, newdata = test)
# Save predictions
pred.stats[pred.stats$num_repeat == repeats & pred.stats$model == "glmnet",
test$rowID] = glmnet.preds
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], glmnet.preds)
## Save variable importance
glmnet.varImp = varImp(glmnet.fit)$importance
# save variable label and order by label
glmnet.varImp$vars = row.names(glmnet.varImp)
glmnet.varImp = arrange(glmnet.varImp, vars)
# Save importance values
varImp.stats[fit.stats.index, sort(x)] = glmnet.varImp$Overall
}
# 2 rf-----------------------------------------------
if(runRF == TRUE) {
## Run inner CV
rf.fit = train(x = train[,x], y = train[,y],
method = "rf", metric = "RMSE",
trControl = fitControl,
tuneGrid = rf.tuneGrid
)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "rf")
## Save final tuning parameters
fit.stats[fit.stats.index, "mtry"] = rf.fit$finalModel$tuneValue
## Predict in independent test set
rf.preds = predict(rf.fit, newdata = test)
# Save predictions
pred.stats[pred.stats$num_repeat == repeats & pred.stats$model == "rf",
test$rowID] = rf.preds
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], rf.preds)
## Save variable importance
rf.varImp = varImp(rf.fit)$importance
# save variable label and order by label
rf.varImp$vars = row.names(rf.varImp)
rf.varImp = arrange(rf.varImp, vars)
# Save importance values
varImp.stats[fit.stats.index, sort(x)] = rf.varImp$Overall
}
# 3 BARTmachine--------------------------------------
if(runBART == TRUE)  {
## Run inner CV
bart.fit = train(x = train[,x], y = train[,y],
method = "bartMachine", metric = "RMSE",
trControl = fitControl,
tuneGrid = bart.tuneGrid
)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "bart")
## Save final tuning parameters
fit.stats[fit.stats.index, c("num_trees", "k.bart", "alpha", "beta", "nu")] =
bart.fit$finalModel$tuneValue
## Predict in independent test set
bart.preds = predict(bart.fit, newdata = test)
# Save predictions
pred.stats[pred.stats$num_repeat == repeats & pred.stats$model == "bart",
test$rowID] = bart.preds
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], bart.preds)
## Save variable importance
bart.varImp = varImp(bart.fit)$importance
# save variable label and order by label
bart.varImp$vars = row.names(bart.varImp)
bart.varImp = arrange(bart.varImp, vars)
# Save importance values
varImp.stats[fit.stats.index, sort(x)] = bart.varImp$Overall
}
}
}
## Collate output for fit statistics and variable importance in list
output = list(fit = fit.stats, varImp = varImp.stats, pred = pred.stats)
head(pred.stats, 1)
tail(pred.stats, 1)
head(fit.stats, 2)
tail(pred.stats, 2)
## Remove prediction output for models that were not run
pred.stats = na.omit(pred.stats)
tail(pred.stats, 2)
round(pred.stats[, 3:ncol(pred.stats)])
preds = pred.stats
## Remove prediction output for models that were not run
preds = na.omit(preds)
## Round predictions
preds[, 3:ncol(preds)] = round(preds[, 3:ncol(preds)])
head(preds, 2)
## Get rowindex
rowindex = paste0("r", 1:(ncol(preds) - 3))
rowindex
## Get rowindex
rowindex = paste0("r", 1:(ncol(preds) - 2))
rowindex
## Round predictions
preds[, rowindex] = round(preds[, rowindex])
head(preds, 2)
head(t(preds[, rowindex]))
##
pred.aggregate = t(preds[, rowindex])
## transpose
tpreds = t(preds[, rowindex])
getmode <- function(v) {
uniqv = unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
head(tpreds)
sapply(getmode(tpreds))
sapply(tpreds, getmode)
?apply
apply(tpreds, 1, getmode)
head(tpreds, 1)
table(tpreds[1,])
apply(tpreds, 1, getmode) %>% t()
apply(tpreds, 1, getmode)
apply(tpreds, 1, getmode) %>% as.vector()
## Get mode
pred.aggregate = apply(tpreds, 1, getmode) %>% as.vector()
## Aggregate pred.stats across models using a voting system
pred.aggregate.stats = pred.aggregate(preds = pred.stats)
pred.aggregate <- function(
preds
) {
## Get rowindex
rowindex = paste0("r", 1:(ncol(preds) - 2))
## Remove prediction output for models that were not run
preds = na.omit(preds)
## Round predictions
preds[, rowindex] = round(preds[, rowindex])
## transpose
tpreds = t(preds[, rowindex])
## Get mode
pred.aggregate = apply(tpreds, 1, getmode) %>% as.vector()
return(pred.aggregate)
}
## Aggregate pred.stats across models using a voting system
pred.aggregate.stats = pred.aggregate(preds = pred.stats)
## Collate output for fit statistics and variable importance in list
output = list(fit = fit.stats,
varImp = varImp.stats,
pred = pred.stats,
pred.aggregate = pred.aggregate.stats)
str(output)
cor(pred.aggregate.stats, dat$t7_bdi_locf)
cor(pred.aggregate.stats, dat$t7_bdi_locf)^2
plot(pred.aggregate.stats, dat$t7_bdi_locf)
summary(pred.aggregate.stats)
sd(pred.aggregate.stats)
summary(dat$t7_bdi_locf)
sd(dat$t7_bdi_locf)
x
with(dat, cor(t0_bdi, t7_bdi_locf))
with(dat, plot(t0_bdi, t7_bdi_locf))
with(dat, cor(t0_bdi, t7_bdi_locf))^2
?mode
with(dat, cor(t0_bdi, t0_bdi_std))
with(dat, plot(t0_bdi, t0_bdi_std))
head(fit.stats)
summary(fit.stats$Rsquared)
with(fit.stats, by(Rsquared, model, summary))
3.958e-02
load("./Results/covariates.base.output.RData")
str(covariates.base.output)
with(covariates.base.output, by(Rsquared, model, summary))
with(covariates.base.output$fit.stats, by(Rsquared, model, summary))
with(covariates.base.output$fit, by(Rsquared, model, summary))
lm.fit = lm(t7_bdi_locf ~ t0_bdi_std + sex_std + age_std, data = train)
summary(lm.fit)
predict(lm.fit = newdata = train)
predict(lm.fit, newdata = train)
cor(predict(lm.fit, newdata = test), test$t7_bdi_locf)
cor(predict(lm.fit, newdata = test), test$t7_bdi_locf)^2
## Define parameters
x = c("t0_bdi_std", "sex_std", "age_std")
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
## Predict in independent test set
glmnet.preds = predict(glmnet.fit, newdata = test)
cor(glmnet.preds, test$t7_bdi_locf)^2
?train
?caret::train
train[,y]
glmnet.fit$finalModel
glmnet.fit$finalModel$beta
rowMeans(glmnet.fit$finalModel$beta)
summary(lm.fit)
cor(glmnet.preds, test$t7_bdi_locf)^2
cor(glmnet.preds, test$t7_bdi_locf)
cor(predict(lm.fit, newdata = test), test$t7_bdi_locf)^2
cor(predict(lm.fit, newdata = test), test$t7_bdi_locf)
?predict.train
predict(glmnet.fit, newdata = test)
predict.train(glmnet.fit, newdata = test)
identical(predict(glmnet.fit, newdata = test), predict.train(glmnet.fit, newdata = test))
extractPrediction(glmnet.fit, test[, x], test[y])
extractPrediction(glmnet.fit, test[, x], test[,y])
extractPrediction(glmnet.fit, testX = test[, x], testY = test[,y])
test[, x]
extractPrediction(glmnet.fit, testX = test[, x], testY = test[,y])
extractPrediction(glmnet.fit, testX = test[, x])
extractPrediction(glmnet.fit, testX = test[, x])
?extractPrediction
glmnet.fit
extractPrediction(glmnet.fit, testX = test[, x])
extractPrediction(glmnet.fit, testX = test[, x, -10])
str(test)
class(test)
extractPrediction(glmnet.fit, testX = data.frame(test[, x, -10]))
extractPrediction(glmnet.fit, testX = matrix(test[, x, -10]))
glmnet.preds
test$ID
which(test$ID)
which(test[test$ID == test$ID,])
nrow(test)
length(glmnet.preds)
which(dat$ID %in% test$ID)
rowMeans(glmnet.fit$finalModel$beta)
test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084
cor(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084, test$t7_bdi_locf)
cor(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084, test$t7_bdi_locf)^2
cor(glmnet.preds, test$t7_bdi_locf)
cor(glmnet.preds, test$t7_bdi_locf)^2
cor(predict(lm.fit, newdata = test), test$t7_bdi_locf)
cor(predict(lm.fit, newdata = test), test$t7_bdi_locf)^2
cor(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084, test$t7_bdi_locf)
cor(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084, test$t7_bdi_locf)^2
glmnet.preds2 = predict(glmnet.fit$finalModel, newdata = test)
glmnet.preds2 = caret::predict(glmnet.fit, newdata = test)
glmnet.preds2 = caret::predict.train(glmnet.fit, newdata = test)
glmnet.preds
glmnet.preds2
?train
?carett::train
?caret::train
trainControl
fitControl
fitControl = trainControl(method = "cv",
number = k.inner)
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
glmnet.preds3 = predict(glmnet.fit, newdata = test)
glmnet.preds
glmnet.preds3
cor(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084, test$t7_bdi_locf)^2
cor(predict(lm.fit, newdata = test), test$t7_bdi_locf)^2
cor(glmnet.preds3, test$t7_bdi_locf)^2
glmnet.fit$finalModel$param
glmnet.fit$finalModel$beta
cor(glmnet.preds3, test$t7_bdi_locf)^2
cor(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084, test$t7_bdi_locf)^2
as.vector(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084)
?caret::predict.glmnet
?caret::predict
summary("as.vector(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084)")
summary(as.vector(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084))
sd(as.vector(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084))
mean(fit.stats$Rsquared)
mean(fit.stats$Rsquared, rm.na = TRUE)
mean(fit.stats$Rsquared, na.rm = TRUE)
median(fit.stats$Rsquared, na.rm = TRUE)
with(dat, cor(t0_bdi, t7_bdi_locf))
cor(predict(lm.fit, newdata = test), test$t7_bdi_locf)^2
cor(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084, test$t7_bdi_locf)^2
summary(as.vector(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084))
sd(as.vector(test$t0_bdi_std * 1.7231747 + test$sex_std * 0.1284409 + test$age_std * -0.3397084))
dat$t7_bdi_locf_std = scale(dat$t7_bdi_locf)
y = "t7_bdi_locf_std"
summary("dat$t7_bdi_locf_std")
summary(dat$t7_bdi_locf_std)
sd(dat$t7_bdi_locf_std)
## Divide data into train and test sets
train = data[data$fold.outer != outer,]
test = data[data$fold.outer == outer,]
## Run inner CV
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
y
dat$t7_bdi_locf_std
class(dat$t7_bdi_locf_std)
class(dat)
data$t7_bdi_locf_std = scale(data$t7_bdi_locf)
## Divide data into train and test sets
train = data[data$fold.outer != outer,]
test = data[data$fold.outer == outer,]
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
class(data)
class(data$t7_bdi_locf_std)
scale(data$t7_bdi_locf)
as.vector(scale(data$t7_bdi_locf))
data$t7_bdi_locf_std = as.vector(scale(data$t7_bdi_locf))
## Divide data into train and test sets
train = data[data$fold.outer != outer,]
test = data[data$fold.outer == outer,]
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
glmnet.preds4 = predict(glmnet.fit, newdata = test)
test$t7_bdi_locf_std
glmnet.preds4
cor(test$t7_bdi_locf_std, glmnet.preds4)
cor(test$t7_bdi_locf_std, glmnet.preds4)^2
