x = clin.vars
df = dat[ids_for_analysis,]
y = "t7_bdi_locf"
k.outer = 5
k.inner = 5
num_repeats = 100
seed = 10
## Subset data to relevant variables only
df = df[, c(x, y)] %>%
mutate_if(is.character, as.factor)
## Set running seed, which is incremented by 1 every time it is used
runningSeed = seed
## Define parameters
cores <- parallel::detectCores()
cores
## Define models
# Random forest
rf_spec = rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_grid = grid_regular(finalize(mtry(), train_df[, x]), min_n(), levels = 5)
finalize()
?finalize
?dials::finalize
finalize(mtry(), df[, x])
ncol(df)
nrow(df)
finalize(mtry(), df[sample(1:nrow(df), size = round(nrow(df)*0.75)), x])
rf_grid = grid_regular(finalize(mtry(), df[, x]), min_n(), levels = 5)
# Elastic net
glmnet_spec = linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet") %>%
set_mode("regression")
glmnet_grid = grid_regular(penalty(), mixture(), levels = 5)
## Create Recipe
rec = recipe(as.formula(paste0(y, " ~ .")), data = train_df) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_impute_knn(all_predictors())
# Create data frames for the two sets:
train_df = training(df_split)
df_split <- initial_split(df, prop = (k.outer - 1)/(k.outer))
df_split
df_split$in_id
df_split$out_id
## Define fold variable
obs.all = nrow(data)
rep_len(sample(1:k.outer), length.out = obs.all)
obs.all
obs.all = nrow(df)
fold.pool.outer = rep_len(sample(1:k.outer), length.out = obs.all)
fold.pool.outer
rep_len(1:k.outer, length.out = obs.all)
## Load packages
library("tidyverse")
.libPaths("C:/Users/nkapp/R")
## Load packages
library("tidyverse")
## Load data
load("./Data/OPTIMA_Cytokine_PreprocessedData.RData")
## Index participants used in analysis
# Index participants with minimum of two BDI observations
ids_with_bdi = dat[, paste0("t", 0:7, "_bdi")] %>% is.na() %>% rowSums < 7
# Index participants with genetic data
ids_with_geneticdata = !is.na(dat$BMI_PRS)
# Show overlap
table(ids_with_bdi, ids_with_geneticdata)
# Index participants with transcriptomic data
ids_with_rnadata = !is.na(dat$rna.PC1) # Present in all individuals
# Index participants with all relevant data
ids_for_analysis = ids_with_bdi & ids_with_geneticdata & ids_with_rnadata
## Define prs.vars
prs.vars = colnames(dat)[grepl("PRS", colnames(dat))]
## Define rna.vars
rna.vars = colnames(dat)[grepl("rna.PC", colnames(dat))]
## Define clinical vars
clin.vars = c("t0_bdi", "t0_madrs", "t0_madrs", "sex", "age", "BMI", "t0_diagn_by_age",
paste0("t0_bsi_", c("soma", "zwan", "unsi", "depr", "angs", "aggr",
"phob", "para", "psyc")),
paste0("t0_pid_", c("negaff", "detach", "psycho", "antago", "disinh")))
## Define parameters
x = clin.vars
df = dat[ids_for_analysis,]
y = "t7_bdi_locf"
k.outer = 5
k.inner = 5
num_repeats = 100
seed = 10
## Subset data to relevant variables only
df = df[, c(x, y)] %>%
mutate_if(is.character, as.factor)
## Set running seed, which is incremented by 1 every time it is used
runningSeed = seed
## Define parameters
obs.all = nrow(df)
cores = parallel::detectCores()
fold_vector = rep_len(1:k.outer, length.out = obs.all)
## Define models
# Random forest
rf_spec = rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("regression")
library("tidymodels")
library("vip")
## Define models
# Random forest
rf_spec = rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_grid = grid_regular(finalize(mtry(), df[, x]), min_n(), levels = 5)
# Elastic net
glmnet_spec = linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet") %>%
set_mode("regression")
glmnet_grid = grid_regular(penalty(), mixture(), levels = 5)
## Assign folds
set.seed(runningSeed)
data$fold.outer = sample(fold.pool.outer)
fold.outer = sample(fold.pool.outer)
## Assign folds
set.seed(runningSeed)
fold_outer = sample(fold_vector)
runningSeed = runningSeed + 1
fold_outer
?nested_cv
?vfold_cv
nested_cv_splits = nested_cv(df,
outside = vfold_cv(v = k.outer, repeats = 1),
inner = vfold_cv(v = k.inner))
k.inner
nested_cv_splits = nested_cv(df,
outside = vfold_cv(v = k.outer, repeats = 1),
inside = vfold_cv(v = k.inner))
nested_cv_splits
nested_cv_splits$inner_resamples
nested_cv_splits$splits
nested_cv_splits$id
nested_cv_splits
nested_cv_splits = nested_cv(df,
outside = vfold_cv(v = k.outer, repeats = 5),
inside = vfold_cv(v = k.inner))
nested_cv_splits
num_repeats = 5
nested_cv_splits = nested_cv(df,
outside = vfold_cv(v = k.outer, repeats = 5),
inside = vfold_cv(v = k.inner))
nested_cv_splits
nested_cv_splits$id2
nested_cv_splits$id
nested_cv_splits$splits
?tidymodels::assessment
?assessment
analysis(nested_cv_splits[[1]])
class(nested_cv_splits)
nested_cv_splits$splits[[1]]
analysis(nested_cv_splits$splits[[1]])
nrow(analysis(nested_cv_splits$splits[[1]]))
nrow(assessment(nested_cv_splits$splits[[1]]))
rf_grid
length(nested_cv_splits$splits)
num_repeats
assessment(nested_cv_splits$splits)
assessment(nested_cv_splits$splits[[1]])
analysis(nested_cv_splits$splits[[1]])
ncol(nested_cv_splits$splits[[1]]$data)
object = nested_cv_splits$splits[[1]]
class(object)
class(object[1])
class(object[2])
object[1]
nrow(object[1])
nrow(object[1]$data)
nrow(object[2]$data)
object[2]$in_id
## Create Recipe
rec = recipe(as.formula(paste0(y, " ~ .")), data = analysis(object)) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_impute_knn(all_predictors())
## Create workflow
rf_wflow =
workflow() %>%
add_model(rf_spec) %>%
add_recipe(rec)
## Define models
# Random forest
rf_spec = rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_grid = grid_regular(finalize(mtry(), df[, x]), min_n(), levels = 5)
rf_fit = rf_wflow %>%
tune_grid(
resamples = analysis(object),
grid = rf_grid,
metrics = metric_set(rmse)
)
nested_cv_splits$splits
nested_cv_splits$resamples
nested_cv_splits$inner_resamples
nested_cv_splits$inner_resamples[[1]]
object = nested_cv_splits$inner_resplits[[1]]
object = nested_cv_splits$inner_resamples[[1]]
assessment(object)
tidy(object)
tidy(nested_cv_splits)
?vfold_cv
training(object)
object = nested_cv_splits$inner_resamples[[1]]
training(object)
class(object)
object = nested_cv_splits$splits[[1]]
training(object)
nrow(object)
length(object$splits)
length(nested_cv_splits$splits)
k.outer
k.inner
num_repeats
object = nested_cv_splits$splits[[1]]
?recipe
## Create Recipe
rec = recipe(as.formula(paste0(y, " ~ .")), data = training(object)) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_impute_knn(all_predictors())
## Create workflow
rf_wflow =
workflow() %>%
add_model(rf_spec) %>%
add_recipe(rec)
rf_fit = rf_wflow %>%
tune_grid(
resamples = training(object),
grid = rf_grid,
metrics = metric_set(rmse)
)
rf_grid
class(training(object))
rf_fit = rf_wflow %>%
tune_grid(
resamples = object,
grid = rf_grid,
metrics = metric_set(rmse)
)
?tune_grid
?rset
num_repeat = 1
## Assign folds
set.seed(runningSeed)
fold_outer = sample(fold_vector)
runningSeed = runningSeed + 1
fold_outer
?sample
?base::sample
## Create permuted Y
df$y_perm = sample(df[,y])
head(df, 2)
train_df = df[fold_outer != num_repeat,]
test_df = df[fold_outer == num_repeat,]
outer = 1
k_inner = k.inner
k_outer = k_outer
?recipe
cat("Repeat no. ", num_repeat)
cat("Repeat no.", num_repeat, "\n")
cat("\nRepeat no.", num_repeat, "\n")
ifelse(outer == 1,
cat("Fold no. 1----"), cat(outer, "----"))
ifelse(outer == 1,
cat("Fold no. 1----"), cat(outer, "----"))
cat(outer, "----")
cat("Fold no. 1----")
outer
if(outer == 1) cat("Fold no. 1----")
else cat(outer, "----")
if(outer == 1) {cat("Fold no. 1----")}
else {cat(outer, "----")}
if(outer == 1) {cat("Fold no. 1----")}
else {cat(outer, "----")}
if(outer == 1) {cat("Fold no. 1----")
} else {cat(outer, "----")}
outer = 2
else {cat(outer, "----")}
if(outer == 1) {cat("Fold no. 1----")
} else {cat(outer, "----")}
?cat
train_df = df[fold_outer != num_repeat,]
test_df = df[fold_outer == num_repeat,]
set.seed(runningSeed)
inner_cv_splits = vfold_cv(train_df, v = k_inner)
runningSeed = runningSeed + 1
## Create Recipe
rec = recipe(as.formula(paste0(y, " ~ .")), data = train_df) %>%
update_role(y_perm, new_role = "id variable") %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_impute_knn(all_predictors())
## Create workflow
rf_wflow =
workflow() %>%
add_model(rf_spec) %>%
add_recipe(rec)
rf_fit = rf_wflow %>%
tune_grid(
resamples = inner_cv_splits,
grid = rf_grid,
metrics = metric_set(rmse)
)
rf_fit
rf_fit %>% collect_metrics()
## Predict
best_rf <- rf_fit %>%
select_best("rmse")
best_rf
final_rf_wflow = rf_wflow %>%
finalize_workflow(best_rf)
final_rf_fit =
final_rf_wflow %>%
fit(train_df)
rf_testing_pred = predict(final_rf_fit, test_df)
rmse_vec(truth = test_df[, y], estimate = rf_testing_pred$.pred)
rsq_trad_vec(truth = test_df[, y], estimate = rf_testing_pred$.pred)
head(train_df, 2)
?recipe
?update_role
## Subset data to relevant variables only
df = df[, c(x, y)] %>%
mutate_if(is.character, as.factor)
colnames(df)[colnames(df) == y] = "y"
## Set running seed, which is incremented by 1 every time it is used
runningSeed = seed
## Define parameters
obs.all = nrow(df)
cores = parallel::detectCores() # to do: remove
fold_vector = rep_len(1:k_outer, length.out = obs.all)
k_outer
k_outer = 5
rm(k.inner)
rm(k.outer)
fold_vector = rep_len(1:k_outer, length.out = obs.all)
## Define models
# Random forest
rf_spec = rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_grid = grid_regular(finalize(mtry(), df[, x]), min_n(), levels = 5)
# Elastic net
glmnet_spec = linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet") %>%
set_mode("regression")
glmnet_grid = grid_regular(penalty(), mixture(), levels = 5)
cat("\nRepeat no.", num_repeat, "\n")
# Assign folds and create permuted Y
set.seed(runningSeed)
fold_outer = sample(fold_vector)
set.seed(runningSeed)
df$y_perm = sample(df[,y])
df$y_perm = sample(df$y)
runningSeed = runningSeed + 1
if(outer == 1) {cat("\tFold no. 1----")
} else {cat(outer, "----", sep = "")}
train_df = df[fold_outer != num_repeat,]
test_df = df[fold_outer == num_repeat,]
set.seed(runningSeed)
inner_cv_splits = vfold_cv(train_df, v = k_inner)
runningSeed = runningSeed + 1
rf_tune_grid = tune_grid(
resamples = inner_cv_splits,
grid = rf_grid,
metrics = metric_set(rmse)
)
?vip
# Create Recipe
rec = create_recipe(train_df, y = "actual")
create_recipe = function(train, y = "actual")  {
if(y == "actual") {
rec = recipe("y ~ .", data = train) %>%
update_role(y_perm, new_role = "id variable")
} else if(y == "permuted") {
y_name_old = y
rec = recipe("y_perm ~ .", data = train) %>%
update_role(y, new_role = "id variable")
} else   {stop("Please define y as 'actual' or 'permuted'")}
rec = rec %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_impute_knn(all_predictors())
return(rec)
}
# Create Recipe
rec = create_recipe(train_df, y = "actual")
?lm
create_recipe = function(train, y = "actual")  {
if(y == "actual") {
rec = recipe(y ~ ., data = train) %>%
update_role(y_perm, new_role = "id variable")
} else if(y == "permuted") {
y_name_old = y
rec = recipe(y_perm ~ ., data = train) %>%
update_role(y, new_role = "id variable")
} else   {stop("Please define y as 'actual' or 'permuted'")}
rec = rec %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_impute_knn(all_predictors())
return(rec)
}
# Create Recipe
rec = create_recipe(train_df, y = "actual")
rec_perm = create_recipe(train_df, y = "permuted")
# Create workflow
rf_wflow = workflow() %>%
add_model(rf_spec)
rf_wflow_perm = rf_wflow %>% add_recipe(rec_perm)
rf_wflow = rf_wflow %>% add_recipe(rec)
# Fit
rf_fit = rf_wflow %>%
tune_grid(resamples = inner_cv_splits, grid = rf_grid, metrics = metric_set(rmse))
rf_fit_perm = rf_wflow_perm %>%
tune_grid(resamples = inner_cv_splits, grid = rf_grid, metrics = metric_set(rmse))
# Select best model
best_rf = rf_fit %>%
select_best("rmse")
best_rf_perm = rf_fit_perm %>%
select_best("rmse")
# Refit to full training data
final_rf_wflow = rf_wflow %>%
finalize_workflow(best_rf)
final_rf_wflow_perm = rf_wflow_perm %>%
finalize_workflow(best_rf_perm)
final_rf_fit = final_rf_wflow %>%
fit(train_df)
final_rf_fit_perm = final_rf_wflow_perm %>%
fit(train_df)
rf_test_pred = predict(final_rf_fit, test_df)
rf_test_pred_perm = predict(final_rf_fit_perm, test_df)
rf_test_pred
create_recipe
name(rf_test_pred)
names(rf_test_pred)
get_fit_indices = function(df, pred, y = "actual")   {
output = data.frame(
RMSE = rmse_vec(truth = df[, ifelse(y == "actual", "y", "y_perm")],
estimate = pred$.pred),
R2 = rsq_trad_vec(truth = df[, ifelse(y == "actual", "y", "y_perm")],
estimate = pred$.pred)
)
return(output)
}
get_fit_indices(test_df, rf_test_pred, y = "actual")
get_fit_indices(test_df, rf_test_pred_perm, y = "perm")
?rsq_trad_vec
?rsq_vec
rsq_vec(truth = test_df[, y], estimate = rf_test_pred$.pred)
rsq_vec(truth = test_df[, "y"], estimate = rf_test_pred$.pred)
rmse_vec(truth = test_df[, "y"], estimate = rf_test_pred$.pred)
get_fit_indices = function(df, pred, y = "actual")   {
output = data.frame(
RMSE = rmse_vec(truth = df[, ifelse(y == "actual", "y", "y_perm")],
estimate = pred$.pred),
R2 = rsq_vec(truth = df[, ifelse(y == "actual", "y", "y_perm")],
estimate = pred$.pred)
)
return(output)
}
get_fit_indices(test_df, rf_test_pred_perm, y = "perm")
get_fit_indices(test_df, rf_test_pred, y = "actual")
cor(test_df[, "y"], rf_test_pred$.pred)^2
cor(test_df[, "y"], rf_test_pred$.pred)
get_fit_indices = function(df, pred, y = "actual")   {
output = c(
RMSE = rmse_vec(truth = df[, ifelse(y == "actual", "y", "y_perm")],
estimate = pred$.pred),
R2 = rsq_vec(truth = df[, ifelse(y == "actual", "y", "y_perm")],
estimate = pred$.pred)
)
return(output)
}
get_fit_indices(test_df, rf_test_pred, y = "actual")
get_fit_indices(test_df, rf_test_pred_perm, y = "perm")
class(get_fit_indices(test_df, rf_test_pred_perm, y = "perm"))
?tibble
output = tibble::tibble(num_repeat, k, algorithm, hyperparameters, fit_indices, fit_indices_perm, fit_indices_diff, vip)
best_rf
get_fit_indices(test_df, rf_test_pred, y = "actual") - get_fit_indices(test_df, rf_test_pred_perm, y = "perm")
final_rf_fit$fit
final_rf_fit$trained
final_rf_fit$post
var_imp(final_rf_fit)
?baguette::var_imp
library("baguette")
temp_output = tibble(
num_repeat = num_repeat,
k = k_outer,
algorithm = "rf",
hyperparameters = best_rf,
fit_indices = get_fit_indices(test_df, rf_test_pred, y = "actual"),
fit_indices_perm = get_fit_indices(test_df, rf_test_pred_perm, y = "perm"),
)
temp_output
str(temp_output)
temp_output$fit_indices$RMSE
temp_output$fit_indices
temp_output[, "RMSE_diff", "R2_diff"] = temp_output$fit_indices - temp_output$fit_indices_perm
temp_output
.libPaths("C:/Users/nkapp/R")
