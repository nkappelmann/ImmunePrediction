ranef(model)$ID
## Extract person-specific random slope for time
model_dat = ranef(model)$ID
## Extract person-specific random slope for time
model_ran_dat = ranef(model)$ID
model_ran_dat$ID = row.names(model_ran_dat)
head(model_ran_dat$)
head(model_ran_dat)
colnames(model_ran_dat) = c("bdi_ran_int", "bdi_ran_slope", "ID")
head(model_ran_dat)
nrow(merge(dat, model_ran_dat, by = "ID"))
nrow(merge(dat, model_ran_dat, by = "ID", all.x = TRUE))
dat = merge(dat, model_ran_dat, by = "ID", all.x = TRUE)
head(dat_l)
dat[is.na(dat$t7_bdi), "ID"]
nrow(dat_l)
dat_l[dat_l$ID %in% dat[is.na(dat$t7_bdi), "ID"], ]
nrow(dat_l[dat_l$ID %in% dat[is.na(dat$t7_bdi), "ID"], ])
## Extract predicted BDI for individuals without t7_bdi
predict_dat = dat_l[dat_l$ID %in% dat[is.na(dat$t7_bdi), "ID"], ]
head(predict_dat)
head(predict(model, predict_dat))
predict(model, predict_dat)
library("TwoSampleMR")
?harmonise_data
pvals = c(0.806, 0.031, 0.821, 0.513, 0.524, 0.783, 0.11, 0.397, 0.707, 0.283, 0.532, 0.454, 0.605, 0.036, 0.143, 0.049, 0.037, 0.497, 0.977)
pvals
p.adjust(pvals, method = "BH")
hist(pvals)
pvals = c(0.497, 0.017, 0.014, 0.005, 0.001, 0.173, 0.680, 0.314, 0.046, 0.052)
p.adjust(pvals, method = "BH")
hist(pvals)
## Fatigue
fatigue.model = 'fatigue ~ bdi_18 + cisr_5'
fatigue.model
pvals
.libPaths()
install.packages("gaston")
library("gaston")
qqplot.pvalues(pvals)
qqplot.pvalues(pvals, pch = ".", cex = 2, thinning = FALSE)
qqplot.pvalues(pvals, pch = ".", cex = 2, thinning = TRUE)
qqplot.pvalues(pvals)
?qqplot.o
?qqplot.pvalues
qqplot.pvalues(pvals, thinning = FALSE, col.abline = brewer.pal(3, "Dark2")[1], col.CB = "lightgray"))
qqplot.pvalues(pvals, thinning = FALSE, col.abline = brewer.pal(3, "Dark2")[1], col.CB = "lightgray")
qqplot.pvalues(pvals, thinning = FALSE, col.abline = brewer.pal(3, "Dark2")[2], col.CB = "lightgray")
exp(-0.033)
exp(-0.033 - 1.96 * 0.017)
exp(-0.033 + 1.96 * 0.017)
exp(-0.070 + 1.96 * 0.052)
exp(-0.070 - 1.96 * 0.052)
exp(-0.070)
exp(-0.106)
exp(-0.106 - 1.96 * 0.1)
exp(-0.106 + 1.96 * 0.1)
pvals.scz = c(0.497, 0.017, 0.014, 0.005, 0.001, 0.173, 0.680, 0.314, 0.046, 0.052)
qqplot.pvalues(pvals.scz, thinning = FALSE, col.abline = brewer.pal(3, "Dark2")[2], col.CB = "lightgray")
pvals.scz = c(0.497, 0.017, 0.014, 0.173, 0.680, 0.314, 0.046, 0.052)
qqplot.pvalues(pvals.scz, thinning = FALSE, col.abline = brewer.pal(3, "Dark2")[2], col.CB = "lightgray")
pvals.scz = c(0.497, 0.017, 0.005, 0.173, 0.680, 0.314, 0.046, 0.052)
qqplot.pvalues(pvals.scz, thinning = FALSE, col.abline = brewer.pal(3, "Dark2")[2], col.CB = "lightgray")
length(dat$ID)
exportPubHelpercsv(dat[, "ID"], file = "InflammationProject_OPTIMA-IDs.csv")
.libPaths("C:/Users/nkapp/R")
.libPaths()
## Load Packages
library("tidyverse")
library("readxl")
library("lme4")
## Load psychometric data
load("/home/nkappelmann/OPTIMA/OPTIMA_Analyses/Data/Processed/02_PsychometricData.RData")
load("./Data/02_PsychometricData.RData")
cyto_dat = readRDS("./Data/02_data_for_analysis.rds")
cyto_dat = readRDS("./Data/02_data_for_analysis_imputed.rds")
head(cyto_dat)
cyto_IDs = read_excel("./Data/01_become_optima_randomization_STD_Controls_Pheno_1219.xlsx")
head(cyto_IDs)
# Save biobank study IDs
cyto_dat$ID.bio = row.names(cyto_dat)
# Merge OPTIMA IDs
cyto_dat = merge(cyto_dat, cyto_IDs[, c("ID", "Lagerung_BC.Tube")],
by.x = "ID.bio", by.y = "Lagerung_BC.Tube", all.x = TRUE)
# Delete duplicates from merging
cyto_dat = cyto_dat[!duplicated(cyto_dat$ID),]
cyto_dat = readRDS("./Data/02_data_for_analysis_imputed.rds")
head(cyto_dat)
row.names(cyto_dat)
# Save biobank study IDs
cyto_dat$ID.bio = cyto_dat$Row.names
head(cyto_dat)
cyto_dat$ID.bio
# Merge OPTIMA IDs
cyto_dat = merge(cyto_dat, cyto_IDs[, c("ID", "Lagerung_BC.Tube")],
by.x = "ID.bio", by.y = "Lagerung_BC.Tube", all.x = TRUE)
# Delete duplicates from merging
cyto_dat = cyto_dat[!duplicated(cyto_dat$ID),]
head(cyto_dat)
# Save variable names in cytokine reference
cyto_ref = data.frame(vars = NA,
labels = colnames(cyto_dat)[10:ncol(cyto_dat)],
stringsAsFactors = FALSE)
# Change column names by excluding hyphens and slashes
colnames(cyto_dat) = gsub("/", "_", colnames(cyto_dat), fixed = TRUE)
colnames(cyto_dat) = gsub("-", ".", colnames(cyto_dat), fixed = TRUE)
colnames(cyto_dat) = gsub(" ", "_", colnames(cyto_dat), fixed = TRUE)
cyto_ref$vars = colnames(cyto_dat)[10:ncol(cyto_dat)]
cyto_ref = cyto_ref[cyto_ref$vars != "ID",]
cyto_ref
## Remove BeCOME data
cyto_dat = cyto_dat[grepl("PTP", cyto_dat$ID, fixed = TRUE),]
## Remove OPTIMA participants without cytokine data
# Note: PTP0114 is excluded as this person clicked through all of their outcome data.
dat = dat[dat$ID %in% cyto_dat$ID,]
## Remove age and sex, so these don't get duplicated
dat[, c("sex", "age")] = NULL
## Merge psychometric and cytokine data
dat = merge(dat, cyto_dat, by = "ID", all.x = TRUE)
colnames(dat)
tail(colnames(dat), 50)
## Create binarised and standardised sex variable
dat$sex_std = ifelse(dat$sex == "female", 0.5, -0.5)
## Create standardised age variable
dat$age_std = scale(dat$age)
## Create standardised t0_bdi variable
dat$t0_bdi_std = scale(dat$t0_bdi)
## Get Top 27% CRP cut-off
dat$hsCRP_inflamed = factor(ifelse(dat$CRP > quantile(dat$hsCRP, prob=1-27/100),
"Inflamed", "Non-Inflamed"),
levels = c("Non-Inflamed", "Inflamed"))
## Ward
dat$ward_type = ifelse(grepl("ST", dat$ward, fixed = TRUE), "Ward", "Day-clinic")
# Country of origin
dat$countryorigin = ifelse(dat$countryorigin == 0, "Germany", "Other")
# Ethnicity
dat$ethnicity = ifelse(dat$ethnicity == 0, "German", "Other")
# Current employment (code retired as extra category)
dat$employed = ifelse(dat$employed == 1, "Employed", "Unemployed")
dat[!is.na(dat$unemploymentreason) & dat$unemploymentreason == "retired", "employed"] = "Retired"
## Set binary variable indicating if cytokine data are complete (following imputation)
cyto_ref[, "na.sum"] = NA
for(i in cyto_ref$vars) {
cyto_ref[cyto_ref$vars == i, "na.sum"] = sum(is.na(dat[, i]))
}
cyto_ref$no.na = ifelse(cyto_ref$na.sum >= 1, 0, 1)
## Create locf variable
dat$bdi_locf = NA
## Run loop to carry forward the last observed bdi-value
for(i in 1:nrow(dat))   {
for(j in 7:0)   {
if(is.na(dat[i, "t7_bdi_locf"]) & !is.na(dat[i, paste0("t", j, "_bdi")]))     {
dat[i, "t7_bdi_locf"] = dat[i, paste0("t", j, "_bdi")]
}
}
}
## Create locf variable
dat$t7_bdi_locf = NA
dat$bdi_locf = NULL
## Run loop to carry forward the last observed bdi-value
for(i in 1:nrow(dat))   {
for(j in 7:0)   {
if(is.na(dat[i, "t7_bdi_locf"]) & !is.na(dat[i, paste0("t", j, "_bdi")]))     {
dat[i, "t7_bdi_locf"] = dat[i, paste0("t", j, "_bdi")]
}
}
}
## Create change variable by subtracting the t0 from the t7_locf score.
dat$bdi_locf_improve = dat$t0_bdi - dat$t7_bdi_locf
## Create empty bdi_locf variable
dat$t7_madrs_locf = NA
## Run loop to carry forward the last observed bdi-value
for(i in 1:nrow(dat))   {
for(j in c(7, 4, 0))   {
if(is.na(dat[i, "t7_madrs_locf"]) & !is.na(dat[i, paste0("t", j, "_madrs")]))     {
dat[i, "t7_madrs_locf"] = dat[i, paste0("t", j, "_madrs")]
}
}
}
## Create change variable by subtracting the t0 from the t7_locf score.
dat$madrs_locf_improve = dat$t0_madrs - dat$t7_madrs_locf
save(dat, file = "./Data/OPTIMA_Cytokine_PreprocessedData.RData")
save(cyto_ref, file = "./Data/Cytokine_Reference.RData")
cyto_ref
library("tidyverse")
library("ggcorrplot")
library("RColorBrewer")
library("caret")
library("glmnet")
library("PubHelper")
.libPaths("C:/Users/nkapp/R")
lapply
sapply
k = 10
obs.all = 114
1:k
rep(1:k, obs.all)
seq
seq(from = 1, to = k, by = 1, length.out = obs.all)
seq(from = 1, to = k, length.out = obs.all)
round(seq(from = 1, to = k, by = 1, length.out = obs.all))
round(seq(from = 1, to = k, length.out = obs.all))
round(seq(from = 1, to = k, length.out = obs.all)) %>% table()
library("tidyverse")
round(seq(from = 1, to = k, length.out = obs.all)) %>% table()
round(seq(from = 0.5, to = k + 0.49, length.out = obs.all)) %>% table()
sample(1:k, n = obs.all)
sample(1:k, obs.all)
sample(1:k, size = obs.all)
sample(1:k, size = obs.all, replace = TRUE)
fold.pool = sample(1:k, size = obs.all, replace = TRUE)
table(fold.pool)
round(0.5)
sample(1:k, size = k, replace = FALSE)
sample(1:k)
?sample
?rep
rep_len(sample(1:k), length.out = obs.all)
table(rep_len(sample(1:k), length.out = obs.all))
length(rep_len(sample(1:k), length.out = obs.all))
library("caret")
fitControl = trainControl(method = "cv",
number = k.inner,
savePredictions = TRUE)
k.inner = 5
fitControl = trainControl(method = "cv",
number = k.inner,
savePredictions = TRUE)
?train
load("./Data/OPTIMA_Cytokine_PreprocessedData.RData")
colnames(dat)
load("./Data/Cytokine_Reference.RData")
head(cyto_ref)
summary(dat$t7_bdi_locf)
summary(dat$t7_bdi_locf, exclude = NULL)
summary(dat$t7_bdi, exclude = NULL)
ids_with_bdi = dat[, paste0("t", 0:7, "_bdi")] %>% is.na() %>% rowSums < 7
ids_with_bdi
data = dat[ids_with_bdi,]
nrow(data) * (4/5) * (4/5)
nrow(data) * (4/5)
nrow(data) * (1/5)
nrow(data) * (1/5) * (1/5)
100*5*5
## Create folds
obs.all = nrow(data)
k.outer = 5
k.inner = 5
num_repeats = 100
fold.pool.outer = rep_len(sample(1:k.outer), length.out = obs.all)
fold.pool.outer
table(fold.pool.outer)
## Define fitControl object for caret
fitControl = trainControl(method = "cv",
number = k.inner,
savePredictions = TRUE)
repeats = 1
## Assign folds
data$fold.outer = sample(fold.pool.outer)
data$fold.outer
outer = 1
## Divide data into train and test sets
train = data[data$fold.outer != outer,]
test = data[data$fold.outer == outer,]
## Run glmnet
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl)
## Test stuff
x = cyto_ref$vars
y = "t7_bdi_locf"
## Run glmnet
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl)
summary(glmnet.fit)
glmnet.fit
predict(glmnet.fit, newdata = test)
glmnet.preds = predict(glmnet.fit, newdata = test)
test[,y]
sqrt( (test[,y] - glmnet.preds)^2 )
sqrt( mean((test[,y] - glmnet.preds)^2) )
plot(glmnet.preds, data[, y])
y
plot(glmnet.preds, test[, y])
cor(glmnet.preds, test[, y], method = "pearson")^2
?RMSE
defaultSummary(data = test[, y], model = glmnet.fit)
RMSE(test[, y], glmnet.preds)
postResample(test[, y], glmnet.preds)
glmnet.r2 = cor(glmnet.preds, test[, y], method = "pearson")^2
glmnet.r2
glmnet.rmse = sqrt( mean((test[,y] - glmnet.preds)^2) )
glmnet.rmse
glmnet.fit.stats = postResample(test[, y], glmnet.preds)
glmnet.fit.stats
num_repeats
fit.stats = data.frame(num_repeat = rep(1:num_repeats, each = k.outer * 3),
k = rep(1:k.outer, num_repeats * 3),
model = rep(c("glmnet", "rf", "BART"), k.outer*num_repeats),
RMSE = NA,
Rsquared = NA,
MAE = NA)
fit.stats
head(fit.stats, 100)
fit.stats = data.frame(num_repeat = rep(1:num_repeats, each = k.outer * 3),
k = rep(1:k.outer, num_repeats * 3),
model = rep(c("glmnet", "rf", "BART"), k.outer*num_repeats),
RMSE = NA,
Rsquared = NA,
MAE = NA,
alpha = NA,
lambda = NA)
glmnet.fit$finalModel
str(glmnet.fit$finalModel)
glmnet.fit$finalModel$tuneValue
head(fit.stats)
which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
model == "glmnet")
which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "glmnet")
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "glmnet")
glmnet.fit$finalModel$tuneValue
class(glmnet.fit$finalModel$tuneValue)
## Save final tuning parameters
fit.stats[fit.stats.index, c("alpha", "lambda")] = glmnet.fit$finalModel$tuneValue
head(fit.stats)
## Predict in independent test set
glmnet.preds = predict(glmnet.fit, newdata = test)
## Save
glmnet.fit.stats = postResample(test[, y], glmnet.preds)
glmnet.fit.stats
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], glmnet.preds)
head(fit.stats)
?trainControl
?train
?caret::train
seq(from = 0, to = 1, by = 0.1)
## Define tuneGrid
glmnet.tuneGrid = data.frame(alpha = rep(seq(from = 0, to = 1, by = 0.1), 10),
lambda = rep(seq(from = 0, to = 1, by = 0.1), each = 10))
glmnet.tuneGrid
## Run inner CV
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
glmnet.fit
?trainControl
## Define fitControl object for caret
fitControl = trainControl(method = "cv",
number = k.inner,
savePredictions = TRUE,
search = "random")
## Run inner CV
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
glmnet.fit
## Define fitControl object for caret
fitControl = trainControl(method = "cv",
number = k.inner,
savePredictions = TRUE)
## Define tuneGrid
glmnet.tuneGrid = data.frame(alpha = rep(seq(from = 0, to = 1, by = 0.2), 10),
lambda = rep(seq(from = 0, to = 1, by = 0.2), each = 10))
## Run inner CV
glmnet.fit = train(x = train[,x], y = train[,y],
method = "glmnet", metric = "RMSE",
trControl = fitControl,
tuneGrid = glmnet.tuneGrid)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "glmnet")
glmnet.fit
head(fit.stats)
## Save final tuning parameters
fit.stats[fit.stats.index, c("alpha", "lambda")] = glmnet.fit$finalModel$tuneValue
## Predict in independent test set
glmnet.preds = predict(glmnet.fit, newdata = test)
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], glmnet.preds)
head(fit.stats)
plot(test[, y], glmnet.preds)
cor(test[, y], glmnet.preds)
cor(test[, y], glmnet.preds)^2
## Run inner CV
rf.fit = train(x = train[,x], y = train[,y],
method = "rf", metric = "RMSE",
trControl = fitControl#,
#tuneGrid = glmnet.tuneGrid
)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "rf")
rf.fit
length(x)
seq(from = 2, to = length(x), length.out = 5)
rf.tuneGrid = data.frame(mtry = round(seq(from = 2, to = length(x), length.out = 5)))
rf.tuneGrid
## Run inner CV
rf.fit = train(x = train[,x], y = train[,y],
method = "rf", metric = "RMSE",
trControl = fitControl,
tuneGrid = rf.tuneGrid
)
## Save index row to save fit.stats output
fit.stats.index = which(fit.stats$num_repeat == repeats &
fit.stats$k == outer &
fit.stats$model == "rf")
rf.fit$finalModel$tuneValue
rf.fit
## Save final tuning parameters
fit.stats[fit.stats.index, "mtry"] = rf.fit$finalModel$tuneValue
## Save final tuning parameters
fit.stats[fit.stats.index, "mtry"] = rf.fit$finalModel$tuneValue
head(fit.stats)
fit.stats[!is.na(fit.stats$RMSE),]
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], rf.preds)
## Predict in independent test set
rf.preds = predict(rf.fit, newdata = test)
# Save fit statistics
fit.stats[fit.stats.index, c("RMSE", "Rsquared", "MAE")] =
postResample(test[, y], rf.preds)
fit.stats[!is.na(fit.stats$RMSE),]
varImp(rf.fit)
?varImp
varImp(rf.fit)$importance
class(varImp(rf.fit)$importance)
rf.varImp = varImp(rf.fit)
rf.varImo
rf.varImp
class(varImp(rf.fit))
as.data.frame(varImp(rf.fit))
data.frame(varImp(rf.fit))
## Save variable importance
rf.varImp = varImp(rf.fit)$importance
str(rf.varImp)
# save variable label and order by label
rf.varImp$vars = row.names(rf.varImp)
head8rf.varImp
head(8)rf.varImp)
head(rf.varImp)
nrow(rf.varImp)
rf.varImp = arrange(rf.varImp, vars)
head(rf.varImp)
## Create output data.frame for variable importance
varImp.stats = fit.stats[, c("num_repeat", "k", "model")]
head(varImp.stats)
sort(x)
varImp.stats[, sort(x)] = NA
head(varImp.stats)
head(rf.varImp)
varImp.stats[fit.stats.index, sort(x)]
t(rf.varImp$Overall)
rf.varImp$Overall
rf.varImp
# Save importance values
varImp.stats[fit.stats.index, sort(x)] = rf.varImp$Overall
varImp.stats[fit.stats.index, sort(x)]
## Save variable importance
glmnet.varImp = varImp(glmnet.fit)$importance
# save variable label and order by label
glmnet.varImp$vars = row.names(glmnet.varImp)
glmnet.varImp = arrange(glmnet.varImp, vars)
varImp(glmnet.fit)
## Run inner CV
bart.fit = train(x = train[,x], y = train[,y],
method = "BARTmachine", metric = "RMSE",
trControl = fitControl#,
#tuneGrid = bart.tuneGrid
)
## Run inner CV
bart.fit = train(x = train[,x], y = train[,y],
method = "bartMachine", metric = "RMSE",
trControl = fitControl#,
#tuneGrid = bart.tuneGrid
)
## Run inner CV
bart.fit = train(x = train[,x], y = train[,y],
method = "bartMachine", metric = "RMSE",
trControl = fitControl#,
#tuneGrid = bart.tuneGrid
)
install.packages("bartMachine")
library("bartMachine")
install.package("rJava")
install.packages("rJava")
library("bartMachine")
install.packages("Java")
.libPaths("C:/Users/nkapp/R")
install.packages(c("bit64", "data.table", "devtools", "httr", "mice", "psych", "psychTools", "remotes", "rvest", "sf", "sys", "tinytex", "xfun", "XML"))
## Load packages
library("tidyverse")
library("ggcorrplot")
library("RColorBrewer")
library("caret")
library("glmnet")
library("bartMachine")
